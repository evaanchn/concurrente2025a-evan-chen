= Paralela25a Evan Chen Cheng
:experimental:
:nofooter:
:source-highlighter: highlightjs
:sectnums:
:stem: latexmath
:toc:
:xrefstyle: short

== Pthreads

[%autowidth]
|=== 
s|# s|Id s|Tipo s|Descripcion
|1 m|link:pthreads/invert[invert] | Ejemplo de clase |Programa serial que invierte numeros enteros dados en la entrada estandar.
|2 m|link:pthreads/hello[hello] | Ejemplo comentado |Primer acercamiento a concurrencia, donde se crea un hilo secundario para saludar al usuario, a la vez que se saluda en el hilo principal.
|3 m|link:pthreads/recursive_hello[recursive_hello] | Ejercicio corto |Se modifica el ejemplo comentado link:pthreads/hello[hello] para que el procedimiento _greet()_ tome como parametro un numero y se despida si es 0, saludar si es 1 y volver a llamarse con un numero menor que el parametro recibido.
|4 m|link:pthreads/hello_w[hello_w] | Ejemplo comentado |Toma como parametro en la linea de comandos, la cantidad de hilos con los que se desea saludar, llamando a greet con este e indicando el numero de hilo.
|5 m|link:pthreads/grandma_lottery[grandma_lottery] | Ejemplo de clase |Representa con hilos de ejecucion a una abuelita que envia a sus dos nietos a comprar loteria. Conceptos: hilo de ejecucion.
|6 m|link:pthreads/hello_iw_pri[hello_iw_pri] | Ejemplo comentado |Se modifica link:pthreads/hello_w[hello_w] tal que todos los hilos tienen registros privados (_private memory_) donde se guardan dos numeros: identificador del hilo y el total de hilos. Se reporta cual hilo de cuantos esta saludando para cada secundario.
|7 m|link:pthreads/hello_iw_shr[hello_iw_shr] | Ejemplo comentado |Se modifica link:pthreads/hello_iw_pri[hello_iw_pri] tal que se almacena la cantidad total de hilos en un registro compartido (_shared memory_), el cual se guarda en cada registro privado.
|8 m|link:pthreads/hello_order_busywait[hello_order_busywait] | Ejemplo comentado |Se modifica link:pthreads/hello_iw_shr[hello_iw_shr] de forma que se ordenan los saludos de hilos secundarios, mediante el uso de la espera activa (while persistente).
|9 m|link:pthreads/team_shot_put[team_shot_put] | Ejemplo de clase |Se simula un enfrentamiento centrado en lanzamiento de peso entre dos equipos, donde se tienen matrices de hilos y registros privados.
|10 m|link:pthreads/create_thread_team[create_thread_tean] | Ejemplo de clase |Se optimiza link:pthreads/team_shot_put[team_shot_put] con registros privados genericos, procedimientos relacionados para crearlos y unirlos, ademas de un registro compartido.
|11 m|link:pthreads/position_race[position_race] | Ejemplo comentado |Representa una carrera entre hilos para reportar en orden, en que posicion quedaron.
|12 m|link:pthreads/delated_busy_wait[delayed_busywait] | Ejemplo de clase |Se modifica link:pthreads/hello_order_busywait[hello_order_busywait] de forma que se "enmascara" la espera activa con sleeps de x microsegundos, sea constante u aleatorio.
|13 m|link:pthreads/hello_order_semaphor[hello_order_semaphor] | Ejemplo comentado |Se utiliza un arreglo de semaforos como alternativa a la espera activa, asegurando impresiones en orden sin efectos secundarios nocivos.
|14 m|link:pthreads/hello_order_cond_safe[hello_order_cond_safe] | Ejemplo comentado |En vez de aplicar un mecanismo de control de concurrencia, se emplea un arreglo de saludos para particionar la memoria compartida en diferentes partes privadas, tal que se elimina condicion de carrera (seguridad condicional).
|15 m|link:pthreads/birthday_pinata[birthday_pinata] | Ejercicio corto |Representa una fiesta de hilos, donde solo uno de estos tiene permitido pegar la pinata a la vez y se turnan hasta que se quiebre.
|16 m|link:pthreads/building_tasks[building_tasks] | Ejemplo de clase |Se representa la construccion de una casa, donde las tareas a hacer tienen dependencia de algunas anteriores. Se trata de completar la obra de manera concurrente, respetando las dependencias de cada tarea.
|17 m|link:pthreads/prod_cons_bound[prod_cons_bound] | Ejemplo comentado |Se resuelve el problema del buffer acotado con dos semaforos, uno para el productor y otro para el consumidor.
|18 m|link:pthreads/prod_cons_unbound[prod_cons_unbound] | Ejemplo comentado |En contraste con el ejemplo anterior, este es la version no acotada del problema productor-consumidor.
|19 m|link:pthreads/network_simul_packet_loss[network_simul_packet_loss] | Ejemplo en clase |Representa una simulacion de red que involucra un productor, un repartidor, varios consumidores y un ensamblador (pierde o convierte paquetes). El programa tiene un fallo de control de concurrencia que causa que ciertos paquetes no se consuman.
|20 m|link:pthreads/network_simul_packet_loss_fix[network_simul_packet_loss_fix] | Ejemplo en clase |Se corrige el defecto del ejemplo pasado, tal que se consumen todos los paquetes creados.
|21 m|link:pthreads/network_simul_packet_loss2[network_simul_packet_loss2] | Ejemplo en clase |Similar al link:pthreads/network_simul_packet_loss[network_simul_packet_loss], pero se traslada al ensamblador tal que primero se ensambla y luego se reparte.
|===

== Tareas
[%autowidth]
|=== 
s|# s|Id s|Titulo s|Descripcion
|1 |link:homeworks/serial[serial] |Simulacion de calor (serial) |Se simula el proceso de equilibrio de laminas, reportando los parametros utilizados, la cantidad de estados transcurridas y la duracion de simulacion.
|2 |link:homeworks/pthreads[pthreads] |Simulacion de calor (concurrente) |Se habilita la opcion de utilizar hilos de ejecucion durante la misma simulacion de calor resuelta en la primera tarea.
|===

== Glosario
=== Oficiales
    1. *Programación serial*: es una manera de programar tal que las instrucciones se ejecutan en secuencia, una despues de la otra (No comienza uno si el anterior no ha terminado). *Analogia*: Una coreografia de baile donde hay una serie de pasos determinados que se deben de ejecutar una tras otra.

    2. *Programación concurrente*: un metaparadigma que implica la programacion #**no serial**#. Una forma de concurrencia es dividir el problema en pedacitos e intercalar entre estos. *Analogia*: Cocinar uno o varios platillos, llevando a cabo pasos de las recetas a la misma vez pero cambiando entre ellas (corto la lechuga de la ensalada mientras se terminan de cocinar el espagueti, y voy alternando entre ambas recetas). 

    3. *Programación paralela*: tipo de programacion donde procesos se llevan a cabo simultaneamente y no hay intercalacion entre tareas. Esta en el tope de la escala de concurrencia. *Analogia*: Los diferentes organos de un cuerpo operan a la misma vez. Por ejemplo, el corazon no espera que uno respire para latir, y a la vez el cuerpo puede estar digiriendo, pensando, caminando, etc.

    4. *Concurrencia de tareas*: Separar asuntos sin buscar mejor rendimiento del programa, sino una colaboracion entre distintos ejecutantes expertos en lo que contribuyen. 

    5. *Paralelismo de datos*: Incremento de rapidez, optimizacion en rendimiento, donde se trata de hacer que el tiempo de ejecucion de un programa baje de mucho a poco. Aqui se involucra el High-performance computing (HPC) y clusters.

    6. *Hilo de ejecución*: Un segmento en la memoria con valores creado y gestionado por el sistema operativo. Este carga los valores del hilo en los registros de un core para poder ejecutar codigo.

    7. *Indeterminismo*: Impredecibilidad de como se comportaran los hilos durante cada ejecucion.

    8. *Memoria privada y compartida*: Datos a los que tienen acceso los hilos: privada, en este sentido,m significa unicamente accesible por cada hilo respectivo, mientras que memoria compartida puede ser accedida por todos los hilos en un _thread team_. 

    9. *Espera activa*: Un tipo de espera que consume todos los recursos de las CPU, por ejemplo, un while seco ejecutado a traves de miles de hilos. Es nociva a la maquina y especialmente prohibido cuando se trata de programacion concurrente (y programacion en general).

    10. *Condición de carrera*: En programacion concurrente, se trata de una situacion donde multiples hilos tratan de modificar y leer un mismo dato ("modificacion concurrente de memoria compartida"). Esto constituye un peligro, dado a que podria no haber consistencia del dato de forma logica.

    11. *Control de concurrencia*: Organizacion de hilos de ejecucion tal que la concurrencia pueda darse sin inconsistencias de datos, a la vez que se controla el tiempo de ejecucion. Al acudir a esto, se frena la concurrencia y se consumen recursos.

    12. *Seguridad condicional*: Un estado entre seguro para hilos y no seguro para hilos, donde la memoria compartida se particiona en secciones tal que se eliminan condiciones de carrera y cada hilo hace su trabajo en su area.

    13. *Exclusión mutua*: Conocido tambien como mutual exclusion, o mutex en ingles, se trata de un mecanismo de control de concurrencia, donde se serializa una region critica, o una region donde se produce condicion de carrera. Esto hace que solo un hilo pueda ejecutar esa seccion de codigo a la vez. *Analogia*: Puente angosto donde solo pasa un carro (hilo) a la vez.

    14. *Semáforo*: Un mecanismo de control de concurrencia que permite concurrencia y orden. A diferencia del mutex, un semaforo no es booleano, sino un valor entero que puede ser positivo, nulo o negativo. Cuando un hilo trata de pasar por un semaforo, le decremente (wait), y si el valor llega a ser negativo, se bloquea. Los siguientes hilos en llegar no podran ejecutar el codigo en la region critica, hasta que los hilos que ya entraron lo vuelvan a incrementar y el valor del semaforo vuelve a ser positivo.

    15. *Descomposición*: Separar un problema en partes luego de identificar unidades de trabajo independientes, tal que se puedan resolver concurrentemente. Puede tratarse de una descomposicion de la solucion, los datos, una exploracion, o los eventos posibles. La descomposicion podria resultar en muchas tareas pequeñas (granulidad fina), o en pocas tareas grandes (granulidad gruesa), los cuales se deben de emplear correctamente dependiendo del problema a resolver.

    16. *Mapeo*: La distribucion del problema descompuesto a distintos ejecutantes para que cumplan el trabajo concurrentemente. Se divide en mapeo estatico (se sabe cuantas unidades de trabajo y trabajadores hay antes de comenzar a trabajar) y mapeo dinamico (se asignan unidades conforme terminan sus trabajos). El primero tiene la ventaja de disminuir la interaccion entre hilos, ser facil de implementar y ser menos costoso, mientras que el segundo rinde mejores distribuciones, aunque sea mas costoso.

    Incremento de velocidad (speedup).

    Barrera.

    Variable de condición.

    Candado de lectura y escritura.

    Eficiencia.

    Comunicación punto a punto entre procesos.

    Comunicación colectiva entre procesos.

    Reducción.

=== Extra

    1. Monitor: Cola threadsafe, o una cola con un mutex para regular el producir y consumir en una cola.